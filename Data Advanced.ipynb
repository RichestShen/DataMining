{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataImporter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Pandas` 数据处理\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值处理\n",
    "\n",
    "> 删除含有缺失值的样本\n",
    "\n",
    "> 替换 / 插补\n",
    "\n",
    "1. 判断数据中是否存在 `NaN`: `pd.isnull(df)`, `pd.notnull(df)`\n",
    "\n",
    "2. 删除含缺失值的样本: `df.dropna(axis='rows', inplace=False)`\n",
    "\n",
    "3. 替换: `df.fillna(value, inplace=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('src/IMDB-Movie-Data.csv')\n",
    "\n",
    "# 判断有无缺失值\n",
    "np.any(pd.isnull(movie))  # True. 即数据集中存在 `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                  False\n",
       "Title                 False\n",
       "Genre                 False\n",
       "Description           False\n",
       "Director              False\n",
       "Actors                False\n",
       "Year                  False\n",
       "Runtime (Minutes)     False\n",
       "Rating                False\n",
       "Votes                 False\n",
       "Revenue (Millions)     True\n",
       "Metascore              True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(movie).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值处理\n",
    "\n",
    "# 方法1: 删除含有缺失值的样本\n",
    "data1 = movie.dropna()\n",
    "# pd.notnull(data1).all()\n",
    "\n",
    "# 方法2: 替换\n",
    "movie['Revenue (Millions)'].fillna(movie['Revenue (Millions)'].mean(), inplace=True)\n",
    "movie['Metascore'].fillna(movie['Metascore'].mean(), inplace=True)\n",
    "\n",
    "# pd.notnull(movie).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 含有标记的缺失值\n",
    "\n",
    "`df.replace(to_replace=, value=)` 替换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\"\n",
    "name = [\"Sample code number\", \"Clump Thickness\", \"Uniformity of Cell Size\", \"Uniformity of Cell Shape\", \"Marginal Adhesion\", \"Single Epithelial Cell Size\", \"Bare Nuclei\", \"Bland Chromatin\", \"Normal Nucleoli\", \"Mitoses\", \"Class\"]\n",
    "\n",
    "data = pd.read_csv(path, names=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample code number             False\n",
       "Clump Thickness                False\n",
       "Uniformity of Cell Size        False\n",
       "Uniformity of Cell Shape       False\n",
       "Marginal Adhesion              False\n",
       "Single Epithelial Cell Size    False\n",
       "Bare Nuclei                    False\n",
       "Bland Chromatin                False\n",
       "Normal Nucleoli                False\n",
       "Mitoses                        False\n",
       "Class                          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 '?' 替换成 NaN\n",
    "data.replace(to_replace='?', value=np.nan)\n",
    "\n",
    "# 删除缺失值\n",
    "data.dropna(inplace=True)\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据离散化\n",
    "\n",
    "在连续属性的值域上, 将值域划分为若干个离散的区间, 最后用不同的符号或整数值代表落在每个子区间的属性值.\n",
    "\n",
    "为了简化数据结构, 减少连续属性值的个数.\n",
    "\n",
    "1. 分组\n",
    "\n",
    "自动分组 `sr = pd.qcut(data, bins)`\n",
    "\n",
    "自定义分组 `sr = pd.cut(data, [])`\n",
    "\n",
    "2. 将分组好的结果转换成 one-hot 编码(哑变量) `pd.get_dummies(sr, prefix=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>身高_(150, 165]</th>\n",
       "      <th>身高_(165, 180]</th>\n",
       "      <th>身高_(180, 195]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No1:165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No2:174</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No3:160</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No4:180</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No5:159</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No6:163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No7:192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No8:184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         身高_(150, 165]  身高_(165, 180]  身高_(180, 195]\n",
       "No1:165              1              0              0\n",
       "No2:174              0              1              0\n",
       "No3:160              1              0              0\n",
       "No4:180              0              1              0\n",
       "No5:159              1              0              0\n",
       "No6:163              1              0              0\n",
       "No7:192              0              0              1\n",
       "No8:184              0              0              1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 准备数据\n",
    "data = pd.Series([165,174,160,180,159,163,192,184], index=['No1:165', 'No2:174','No3:160', 'No4:180', 'No5:159', 'No6:163', 'No7:192', 'No8:184'])\n",
    "\n",
    "# 分组\n",
    "# 自动分组\n",
    "sr = pd.qcut(data, 3)\n",
    "sr.value_counts()  # 看每一组有几个数据\n",
    "\n",
    "# 转换成one-hot编码\n",
    "pd.get_dummies(sr, prefix=\"height\")\n",
    "\n",
    "# 自定义分组\n",
    "bins = [150, 165, 180, 195]\n",
    "sr = pd.cut(data, bins)\n",
    "# get_dummies\n",
    "pd.get_dummies(sr, prefix=\"身高\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并\n",
    "\n",
    "按方向拼接: `pd.concat([data1, data2], axis=0)` 默认竖直拼接\n",
    "\n",
    "按索引拼接: `pd.merge(left=, right=, how='inner', on=)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分组与聚合\n",
    "\n",
    "`DataFrame.groupby(key, as_index=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color\n",
       "green    2.75\n",
       "red      4.20\n",
       "white    5.56\n",
       "Name: price1, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = DataFrame({'color': ['white','red','green','red','green'], 'object': ['pen','pencil','pencil','ashtray','pen'],'price1':[5.56,4.20,1.30,0.56,2.75],'price2':[4.75,4.12,1.60,0.75,3.15]})\n",
    "\n",
    "col.groupby(by='color')['price1'].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
